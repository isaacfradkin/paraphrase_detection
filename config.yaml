generate_dataset:
  saving_folder: "data/text_generation"
  dataset_name: "dataset.csv"
  model_name : "falcon-1b" # "gpt2" or "falcon-1b"
  prompt_list : ["Most people start the day by", 
    "Today I am feeling", 
    "The thing I like most in the world is",
    "When I was a little kid", 
    "I had a terrifying dream last night in which",
    "I worry a lot about"]
  n_simulations : 10 # number of simulation by prompt
  target_length : 100 # max length of the generated text
  min_temperature : 0.9
  max_temperature : 5
  top_p:  0.95
  retrospective_span: 100

paraphrase_dataset:
  paraphrase_generator:
    # Default model for ParaphraseGenerator
    default_model: "ibm/qcpg-sentences"

  paraphrase_models:
    - "Vamsi/T5_Paraphrase_Paws"
    - "umarin/chatgpt_paraphraser_on_T5_base"
    - "prithivida/parrot_paraphraser_on_T5"
    - "stanford-oval/paraphraser-bart-large"

  quality_control_models:
    - "ibm/qcpg-sentences"
    - "ibm/qcpg-captions"
    - "ibm/qcpg-questions"

  parrot_kwargs:
    diversity_ranker: "levenshtein"
    do_diverse: 9
    max_return_phrases: 10
    adequacy_threshold: 0.1
    fluency_threshold: 0.1

  quality_control_kwargs:
    lexical: 0.3
    syntactic: 0.5
    semantic: 0.8
